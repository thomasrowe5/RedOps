# RedOps Hardening Overview

This guide documents the defensive assumptions for the lab deployment and the security controls currently enforced by the orchestrator stack.

## Threat Model

### Lab Adversary
- The orchestrator is intentionally exposed only to traffic from the internal lab network. Host-based middleware enforces this by denying requests that originate outside the RFC1918 ranges permitted for testing.【F:orchestrator/app/main.py†L55-L93】
- Adversarial activity is generated by research agents that simulate red-team tradecraft. Controls focus on preventing these agents from escaping their sandbox or flooding shared infrastructure while still allowing high-volume experimentation.

### Insider Risk
- Lab operators and developers are treated as potentially malicious insiders who already have network reachability. Privileged endpoints therefore require `operator`-role tokens and are limited to read-only inspection of orchestration state (e.g., Prometheus metrics).【F:README.md†L9-L27】【F:orchestrator/app/main.py†L705-L717】
- Audit trails and immutable hash chaining protect against unauthorized tampering with run records, ensuring forensic fidelity even when insiders possess file-system access.【F:orchestrator/app/audit.py†L20-L118】

## Controls Implemented

### JSON Web Tokens (JWT)
- All write paths (`/events`, `/responses`) and operator endpoints validate signed JWTs generated from a shared secret provided via `REDOPS_JWT_SECRET`. Tokens encode caller identity and role, and requests without a valid signature or role mapping are rejected.【F:README.md†L9-L27】【F:orchestrator/app/auth.py†L17-L104】
- Lab-only `/token` helper endpoint issues development credentials once the secret is configured, simplifying local rotation during exercises.【F:orchestrator/app/main.py†L721-L748】

### Adaptive Rate Limiting
- Token-bucket enforcement throttles per-run, per-agent event ingestion using configurable burst and refill limits (`REDOPS_RATE_LIMIT_BURST`, `REDOPS_RATE_LIMIT_RATE`). Requests above quota return HTTP 429, preventing unbounded event floods from rogue agents.【F:orchestrator/app/main.py†L200-L335】

### Non-Root Execution
- The orchestrator container is built on a dedicated `nonroot` user and group, with application files owned by the unprivileged account. This prevents privilege escalation if the service is compromised.【F:orchestrator/Dockerfile†L1-L17】

### Seccomp and Capability Hardening
- `docker-compose` applies `no-new-privileges`, drops all Linux capabilities, mounts a read-only root filesystem, and constrains the process with the custom `docker/seccomp-redops.json` profile, shrinking the attack surface for container escapes.【F:lab/docker-compose.yml†L9-L58】

### Append-Only Audit Chain
- Every run emits structured NDJSON entries whose hashes are chained to the previous record. Verification fails fast on any missing or modified record, enabling tamper detection during after-action reviews.【F:orchestrator/app/audit.py†L56-L118】

### Prometheus Metrics Exposure
- Request timing, queue depth, and write success/failure counters are exported at `/metrics` and require an `operator` role token. Instrumentation updates gauges after each enqueue/dequeue cycle and records detection counts for situational awareness.【F:orchestrator/app/main.py†L127-L158】【F:orchestrator/app/main.py†L705-L717】【F:orchestrator/app/metrics.py†L9-L74】

## Redis Queue Enablement

1. Deploy a Redis 5+ instance reachable from the orchestrator (the lab profile assumes `redis://redis:6379/0`).
2. Set `REDOPS_QUEUE_DRIVER=redis` in the orchestrator environment before startup. Optional tuning variables include `REDIS_URL`, `REDOPS_QUEUE_TIMEOUT`, and `REDOPS_QUEUE_MAX` for stream back pressure.
3. Restart the service. The orchestrator automatically instantiates the Redis-backed `JobBus`, preserves queue depth telemetry, and continues to enforce rate limiting per run.【F:orchestrator/app/main.py†L162-L178】【F:orchestrator/app/redis_bus.py†L19-L116】

## Load Generation and Metrics Interpretation

### Running the Load Generator
1. Ensure the orchestrator is running and that you have an `agent_red` token.
2. Execute the async load generator:
   ```bash
   python tools/loadgen.py --agents 5 --eps 2 --duration 60 \
       --run-id bench --base-url http://localhost:8000 \
       --endpoint /runs/<run-id>/events
   ```
3. The tool reports aggregate throughput, error counts, and latency percentiles. Use these figures to verify rate-limit tuning before observing Prometheus metrics.【F:tools/loadgen.py†L1-L145】

### Reading Prometheus Signals
- **`redops_events_total`** increases with every accepted event and detection, helping correlate ingestion volume with agent activity.【F:orchestrator/app/metrics.py†L20-L49】
- **`redops_queue_depth`** tracks per-run backlog; rising gauges indicate downstream pressure in Redis or the in-memory queue.【F:orchestrator/app/metrics.py†L32-L40】【F:orchestrator/app/main.py†L123-L158】
- **`redops_write_batches_total` / `redops_write_errors_total`** summarize durability health of the batch writer; sustained growth in errors suggests I/O failures.【F:orchestrator/app/metrics.py†L41-L61】【F:orchestrator/app/main.py†L150-L166】
- **`redops_requests_latency_seconds`** histograms capture handler latency by method and endpoint. Compare these with load generator percentiles to identify saturation or rate-limiting responses.【F:orchestrator/app/metrics.py†L63-L75】【F:orchestrator/app/main.py†L336-L377】

Scrape the endpoint with Prometheus or use `curl` while supplying an operator token:
```bash
curl -H "Authorization: Bearer $OPERATOR_TOKEN" http://localhost:8000/metrics
```
This combined telemetry pipeline surfaces both orchestrator back pressure and control-plane health during red-team simulations.【F:orchestrator/app/main.py†L705-L717】
